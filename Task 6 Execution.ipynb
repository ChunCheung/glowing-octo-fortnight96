{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.python import keras # High level, easy to use, intuitive DNN library\n",
    "from tensorflow.python.keras.datasets import mnist # Digits data\n",
    "from tensorflow.python.keras.models import Sequential, Model # Method that helps us build the model,\n",
    "                                                      # by stacking the layers together\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten # Different layers as part of the network;\n",
    "# Dense layer - is your regular linear layer, # Dropt out sets some of the weights to zero randomly\n",
    "# to prevent from overfitting; Flatten does exactly what it sounds like, flattens the multi-dimensional array\n",
    "# into one dimension\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D #2D convolution array, and Max Pooling array\n",
    "from tensorflow.python.keras import backend as K\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "obs = pd.read_csv('/modules/cs342/Assignment2/test_set.csv',dtype={'flux':'float32'},usecols=[0,2])\n",
    "test_meta=pd.read_csv(\"/modules/cs342/Assignment2/test_set_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "t0=time()\n",
    "res = obs.assign(ValNum=obs.groupby('object_id').cumcount()+1)\\\n",
    "        .pivot(index='object_id', columns='ValNum', values='flux')\\\n",
    "        .reset_index()\n",
    "t1=time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.3695111275\n",
      "18.5672860146\n",
      "17.8629670143\n",
      "18.1061530113\n",
      "18.1925430298\n",
      "18.4580729008\n",
      "18.4484801292\n",
      "20.7398569584\n",
      "20.2759490013\n",
      "3.44456601143\n"
     ]
    }
   ],
   "source": [
    "#converts testing set to be entered into conv layer\n",
    "from time import time\n",
    "a=0\n",
    "for obs in pd.read_csv('/modules/cs342/Assignment2/test_set.csv',chunksize=50000000,\n",
    "                   dtype={'flux':'float32'},usecols=[0,3]):\n",
    "    t0=time()\n",
    "    res = obs.assign(ValNum=obs.groupby('object_id').cumcount()+1)\\\n",
    "        .pivot(index='object_id', columns='ValNum', values='flux')\\\n",
    "        .reset_index()\n",
    "    if a==0:\n",
    "        #output.to_csv(\"/var/tmp/kdecache-u1403100/features_1.csv\")\n",
    "        time_data=res\n",
    "        a=1\n",
    "        \n",
    "    else:\n",
    "        #output.to_csv(\"/var/tmp/kdecache-u1403100/features_1.csv\", mode='a',header=False)\n",
    "        time_data=pd.concat([time_data,res],axis=0)\n",
    "       \n",
    "    t1=time()\n",
    "    print(t1-t0)\n",
    "time_data=time_data.drop_duplicates(subset='object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts training set to be entered into conv layer\n",
    "obs=pd.read_csv('/dcs/17/u1403100/Downloads/A2/training_set.csv',dtype={'flux':'float32'},usecols=[0,3])\n",
    "train = obs.assign(ValNum=obs.groupby('object_id').cumcount()+1)\\\n",
    "        .pivot(index='object_id', columns='ValNum', values='flux')\\\n",
    "        .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_data=time_data.fillna(0)\n",
    "train=train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x=train.drop(['object_id'],axis=1).values\n",
    "train_y=pd.get_dummies(meta['target']).values\n",
    "test_x=time_data.drop(['object_id'],axis=1).values\n",
    "train_x = train_x.reshape(7848,352,1)\n",
    "test_x = test_x.reshape(3492890,352,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convolution Neural Network from keras cdocumentation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras import optimizers\n",
    "seq_length = 352\n",
    "inp =  Input(shape=(352, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.5847 - acc: 0.3299     \n",
      "Epoch 2/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.5602 - acc: 0.3110     \n",
      "Epoch 3/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.6186 - acc: 0.3110     \n",
      "Epoch 4/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.7250 - acc: 0.3118     \n",
      "Epoch 5/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.7163 - acc: 0.3137     \n",
      "Epoch 6/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.6805 - acc: 0.3138     \n",
      "Epoch 7/7\n",
      "7848/7848 [==============================] - 6s - loss: 2.6669 - acc: 0.3151     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6113cd6310>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=32, nb_epoch=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492704/3492890 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred=model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    output = pd.DataFrame({\n",
    "                        'Class_6':pred[:,0],\n",
    "                        'Class_15':pred[:,1],\n",
    "                        'Class_16':pred[:,2],\n",
    "                        'Class_42':pred[:,3],\n",
    "                        'Class_52':pred[:,4],\n",
    "                        'Class_53':pred[:,5],\n",
    "                        'Class_62':pred[:,6],\n",
    "                        'Class_64':pred[:,7],\n",
    "                        'Class_65':pred[:,8],\n",
    "                        'Class_67':pred[:,9],\n",
    "                        'Class_88':pred[:,10],\n",
    "                        'Class_90':pred[:,11],\n",
    "                        'Class_92':pred[:,12],\n",
    "                        'Class_95':pred[:,13]                              \n",
    "                       })\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ouput' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-2abff32c14a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_99'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.06\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mouput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/dcs/17/u1403100/Downloads/A2/Task6.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ouput' is not defined"
     ]
    }
   ],
   "source": [
    "test_meta=pd.read_csv(\"/modules/cs342/Assignment2/test_set_metadata.csv\")\n",
    "output.index = np.arange(0, len(output))\n",
    "output['object_id']=test_meta['object_id']\n",
    "output['class_99']=0.06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"/dcs/17/u1403100/Downloads/A2/Task6.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
