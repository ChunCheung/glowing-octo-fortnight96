{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sci\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Max/Downloads/data/train_women_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(np.log(y_pred[i] + 1) - np.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(y_pred[i]-y[i]) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dictionary=df[['brand_name','price']].groupby('brand_name').mean()\\ndi=dictionary.to_dict()['price']\\ndf['brand_name']=df.loc[:100000,'brand_name'].replace(di)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dictionary=df[['brand_name','price']].groupby('brand_name').mean()\n",
    "di=dictionary.to_dict()['price']\n",
    "df['brand_name']=df.loc[:100000,'brand_name'].replace(di)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('train_id',axis=1,inplace=True)\n",
    "df.loc[:, df.dtypes == np.int64]=df.loc[:, df.dtypes == np.int64].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['category2','category3','brand_name']]= df[['category2','category3','brand_name']].astype('category')\n",
    "df_x=df.drop(['name','item_description','category_name','category','category2','category3' ,'price','brand_name'],axis=1)\n",
    "df_y=df['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating one hot encoding array for category2 and category3\n",
    "le = preprocessing.LabelEncoder()\n",
    "data = le.fit_transform(df.category2)\n",
    "data = array(data)\n",
    "\n",
    "category2 = to_categorical(data)\n",
    "# invert encoding\n",
    "#inverted = argmax(encoded[0])\n",
    "#print(inverted)\n",
    "#print(type(encoded))\n",
    "data = le.fit_transform(df.category3)\n",
    "data = array(data)\n",
    "category3 = to_categorical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x=np.concatenate([df_x.values,category2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.662823955580706\n",
      "37.43760293588879\n",
      "36.86345688161297\n",
      "37.533079104009985\n",
      "37.7355554390166\n",
      "37.51227529884018\n",
      "36.940089786095974\n",
      "37.60544285864586\n",
      "37.81994843585145\n",
      "37.597873296308855\n",
      "37.02718045593601\n",
      "37.68652203577686\n",
      "37.89527262899069\n",
      "37.67601149740581\n",
      "37.1053702003642\n",
      "37.76098879389184\n",
      "37.972358839840886\n",
      "37.75500611758901\n",
      "37.18365699676178\n",
      "37.83366822642087\n",
      "           0          1          2          3          4    5    6    7    8  \\\n",
      "0   0.000000   0.000000   0.000000   0.000000   0.000000  0.0  0.0  0.0  0.0   \n",
      "1  37.533079  37.605443  37.686522  37.760989  37.833668  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     9  \n",
      "0  0.0  \n",
      "1  0.0  \n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "df2 = pd.DataFrame(np.zeros((1,10)) ) \n",
    "for k in range(5):\n",
    "    kf = KFold(n_splits=4)\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        result=[]\n",
    "        X_train, X_test = df_x[train_index], df_x[test_index]\n",
    "        y_train, y_test = df_y[train_index], df_y[test_index]\n",
    "\n",
    "        neigh = linear_model.Lasso(alpha=0.05*(k+1))\n",
    "        neigh.fit(X_train,y_train)\n",
    "        err=rmse(neigh.predict(X_test),y_test)\n",
    "        result.append(err)\n",
    "        \n",
    "        \n",
    "    df2.iloc[0,k]=np.average(result)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "df2 = pd.DataFrame(np.zeros((1,10)) ) \n",
    "for k in range(5):\n",
    "    kf = KFold(n_splits=4)\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        result=[]\n",
    "        X_train, X_test = df_x[train_index], df_x[test_index]\n",
    "        y_train, y_test = df_y[train_index], df_y[test_index]\n",
    "\n",
    "        neigh = linear_model.Lasso(alpha=0.05*(k+1))\n",
    "        neigh.fit(X_train,y_train)\n",
    "        err=rmse(neigh.predict(X_test),y_test)\n",
    "        result.append(err)\n",
    "        \n",
    "        \n",
    "    df2.iloc[0,k]=np.average(result)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "df2 = pd.DataFrame(np.zeros((5,5)) )\n",
    "hidden_layer_sizes=[(50,)(100,),(50,50),(100,50) (50,50,50)]\n",
    "for i in range(5):\n",
    "    for k in range(5):\n",
    "        kf = KFold(n_splits=4)\n",
    "        for train_index, test_index in kf.split(df):\n",
    "            result=[]\n",
    "            X_train, X_test = df_x[train_index], df_x[test_index]\n",
    "            y_train, y_test = df_y[train_index], df_y[test_index]\n",
    "\n",
    "            neigh = linear_model.sklearn.neural_network.MLPClassifier(alpha=0.05*(k+1),hidden_layer_sizes=hidden_layer_sizes[i])\n",
    "            neigh.fit(X_train,y_train)\n",
    "            err=rmse(neigh.predict(X_test),y_test)\n",
    "            result.append(err)\n",
    "\n",
    "\n",
    "        df2.iloc[i,k]=np.average(result)\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators=[30,50, 100, 150, 200]\n",
    "max_depth=[10, 20, 40, 70, None]\n",
    "i=0\n",
    "df2 = pd.DataFrame(np.zeros((5,10)) ) \n",
    "for i in range(5):\n",
    "    for k in range(5):\n",
    "        kf = KFold(n_splits=4)\n",
    "        for train_index, test_index in kf.split(df):\n",
    "            result=[]\n",
    "            X_train, X_test = df_x[train_index], df_x[test_index]\n",
    "            y_train, y_test = df_y[train_index], df_y[test_index]\n",
    "\n",
    "            neigh = RandomForestRegressor(random_state = 42,n_estimators=n_estimators[i],max_depth=max_depth[k])\n",
    "            neigh.fit(X_train,y_train)\n",
    "            err=rmse(neigh.predict(X_test),y_test)\n",
    "            result.append(err)\n",
    "        \n",
    "        \n",
    "    df2.iloc[i,k]=np.average(result)\n",
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
